{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install dival --break-system-packages\n",
    "%pip install tqdm --break-system-packages\n",
    "%pip install matplotlib --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1838c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4118089c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dival import get_standard_dataset\n",
    "\n",
    "dataset = get_standard_dataset(\"lodopab\", impl=\"skimage\")\n",
    "\n",
    "train_dataset = dataset.create_torch_dataset(part=\"train\")\n",
    "test_dataset = dataset.create_torch_dataset(part=\"test\")\n",
    "val_dataset = dataset.create_torch_dataset(part=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fbaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3140de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetGenerator(nn.Module):\n",
    "    \"\"\"Unet-like Encoder-Decoder model\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        def conv_block(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        # Encoder (halved channels)\n",
    "        self.enc1 = conv_block(1, 32)\n",
    "        self.pool1 = nn.MaxPool2d(2)  # 1000x513 -> 500x256\n",
    "        self.enc2 = conv_block(32, 64)\n",
    "        self.pool2 = nn.MaxPool2d(2)  # 500x256 -> 250x128\n",
    "        self.enc3 = conv_block(64, 128)\n",
    "        self.pool3 = nn.MaxPool2d(2)  # 250x128 -> 125x64\n",
    "        self.enc4 = conv_block(128, 256)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = conv_block(256, 512)\n",
    "\n",
    "        # Decoder (halved channels accordingly)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = conv_block(256 + 128, 256)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = conv_block(128 + 64, 128)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = conv_block(64 + 32, 64)\n",
    "\n",
    "        self.final = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "        # Resize output to 362x362\n",
    "        self.resize = nn.AdaptiveAvgPool2d((362, 362))\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        e4 = self.enc4(self.pool3(e3))\n",
    "\n",
    "        b = self.bottleneck(e4)\n",
    "\n",
    "        d3 = self.up3(b)\n",
    "        d3 = self.dec3(torch.cat([d3, e3], dim=1))\n",
    "\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))\n",
    "\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = F.interpolate(d1, size=e1.shape[2:], mode=\"bilinear\", align_corners=False)\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))\n",
    "\n",
    "        out = self.final(d1)\n",
    "        return self.resize(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d707210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Basic block\"\"\"\n",
    "    def __init__(self, inplanes, outplanes, kernel_size=4, stride=2, padding=1, norm=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(inplanes, outplanes, kernel_size, stride, padding)\n",
    "        self.isn = None\n",
    "        if norm:\n",
    "            self.isn = nn.InstanceNorm2d(outplanes)\n",
    "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        fx = self.conv(x)\n",
    "        \n",
    "        if self.isn is not None:\n",
    "            fx = self.isn(fx)\n",
    "            \n",
    "        fx = self.lrelu(fx)\n",
    "        return fx\n",
    "    \n",
    "    \n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    \"\"\"Conditional Discriminator\"\"\"\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.block1 = BasicBlock(6, 64, norm=False)\n",
    "        self.block2 = BasicBlock(64, 128)\n",
    "        self.block3 = BasicBlock(128, 256)\n",
    "        self.block4 = BasicBlock(256, 512)\n",
    "        self.block5 = nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
    "\n",
    "        self.cond_resize = nn.AdaptiveAvgPool2d((362, 362))\n",
    "        \n",
    "    def forward(self, x, cond):\n",
    "        cond = self.cond_resize(cond) # Resize condition to match x's size\n",
    "        x = torch.cat([x, cond], dim=1)\n",
    "        \n",
    "        fx = self.block1(x)\n",
    "        fx = self.block2(fx)\n",
    "        fx = self.block3(fx)\n",
    "        fx = self.block4(fx)\n",
    "        fx = self.block5(fx)\n",
    "        \n",
    "        return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self, alpha=100):\n",
    "        super().__init__()\n",
    "        self.alpha=alpha\n",
    "        self.bce=nn.BCEWithLogitsLoss()\n",
    "        self.l1=nn.L1Loss()\n",
    "        \n",
    "    def forward(self, fake, real, fake_pred):\n",
    "        fake_target = torch.ones_like(fake_pred)\n",
    "        loss = self.bce(fake_pred, fake_target) + self.alpha* self.l1(fake, real)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class DiscriminatorLoss(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, fake_pred, real_pred):\n",
    "        fake_target = torch.zeros_like(fake_pred)\n",
    "        real_target = torch.ones_like(real_pred)\n",
    "        fake_loss = self.loss_fn(fake_pred, fake_target)\n",
    "        real_loss = self.loss_fn(real_pred, real_target)\n",
    "        loss = (fake_loss + real_loss) / 2\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UnetGenerator().to(device)\n",
    "discriminator = ConditionalDiscriminator().to(device)\n",
    "\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "g_criterion = GeneratorLoss(alpha=100)\n",
    "d_criterion = DiscriminatorLoss()\n",
    "mse_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b671706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def save_state(epoch, generator, discriminator, g_optimizer, d_optimizer):\n",
    "    checkpoint_dir = \"/workspace/checkpoints\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"generator_state_dict\": generator.state_dict(),\n",
    "        \"discriminator_state_dict\": discriminator.state_dict(),\n",
    "        \"g_optimizer_state_dict\": g_optimizer.state_dict(),\n",
    "        \"d_optimizer_state_dict\": d_optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 50\n",
    "patience = 5\n",
    "\n",
    "best_weights_g = None\n",
    "best_weights_d = None\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "early_stopping_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(\"Training started\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ge_loss = 0.0\n",
    "    de_loss = 0.0\n",
    "\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # Training loop with progress bar\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "    for sino, img in train_bar:\n",
    "        sino = sino.unsqueeze(1).to(device, non_blocking=True)  # [B, 1, H, W]\n",
    "        img = img.unsqueeze(1).to(device, non_blocking=True)    # [B, 1, H, W]\n",
    "\n",
    "        # Generator`s loss\n",
    "        fake = generator(sino)\n",
    "        fake_pred = discriminator(fake, sino)\n",
    "        g_loss = g_criterion(fake, img, fake_pred)\n",
    "\n",
    "        # Discriminator`s loss\n",
    "        fake = generator(sino).detach()\n",
    "        fake_pred = discriminator(fake, sino)\n",
    "        real_pred = discriminator(img, sino)\n",
    "        d_loss = d_criterion(fake_pred, real_pred)\n",
    "\n",
    "        # Generator`s params update\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Discriminator`s params update\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        ge_loss += g_loss.item()\n",
    "        de_loss += d_loss.item()\n",
    "\n",
    "    ge_loss /= len(train_loader)\n",
    "    de_loss /= len(train_loader)\n",
    "\n",
    "    # Validation loop with progress bar\n",
    "    generator.eval()\n",
    "    running_loss = ge_loss + de_loss\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
    "        for sino, img in val_bar:\n",
    "            sino = sino.unsqueeze(1).to(device, non_blocking=True)\n",
    "            img = img.unsqueeze(1).to(device, non_blocking=True)\n",
    "\n",
    "            output = generator(sino)\n",
    "            loss = mse_criterion(output, img)\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Save checkpoints every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        save_state(epoch, generator, discriminator, g_optimizer, d_optimizer)\n",
    "\n",
    "    # Check if this is the best model so far\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_weights_g = generator.state_dict()\n",
    "        best_weights_d = discriminator.state_dict()\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss > (1.01 * val_losses[-1] if val_losses else float(\"inf\")):\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    train_losses.append(running_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"Train Loss: {running_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generator(checkpoint_path, generator, device=\"cuda\"):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    generator.load_state_dict(checkpoint[\"generator_state_dict\"])\n",
    "    generator.to(device)\n",
    "    generator.eval()\n",
    "\n",
    "    return generator, checkpoint[\"epoch\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
